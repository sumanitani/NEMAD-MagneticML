{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72df9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ensemble Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "csv_path = (\"filepath\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "FEATURES = [\n",
    "    'Nb', 'Ca', 'Tm', 'S', 'Sb', 'U', 'Mo', 'Sm', 'I', 'Ag', 'Ir', 'Pu', 'Hf', 'Sc', 'Br', 'Ni',\n",
    "    'Co', 'Zr', 'W', 'Tb', 'Mn', 'Fe', 'Cr', 'Pb', 'Si', 'Ba', 'Nd', 'Cs', 'N', 'Lu', 'Se', 'Pt',\n",
    "    'Pr', 'Au', 'La', 'Re', 'Zn', 'Os', 'Ti', 'Be', 'Ce', 'Cu', 'In', 'Rb', 'Tl', 'F', 'Dy', 'V',\n",
    "    'Er', 'Ho', 'Pd', 'H', 'B', 'C', 'Cl', 'P', 'Hg', 'Sr', 'Gd', 'Ga', 'K', 'Te', 'Th', 'Yb',\n",
    "    'Al', 'Tc', 'Np', 'Ta', 'Rh', 'Ru', 'As', 'Cd', 'Li', 'Sn', 'Ge', 'Mg', 'Eu', 'Na', 'O', 'Y', 'Bi',\n",
    "    'Avg_Atomic_Number','Average_Weight','Average_Electronegativity',\n",
    "    'Magnetic_proportion','Entropy','average_period','avg_magnetic_moment',\n",
    "    'average_group','Rare_Earth_proportion'\n",
    "]\n",
    "TARGET = 'Mean_TN_K'\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]\n",
    "\n",
    "\n",
    "bins = pd.cut(\n",
    "    y,\n",
    "    bins=[-np.inf, 8, 20, 50, 125, 300, np.inf],\n",
    "    labels=False\n",
    ")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, bins_train, bins_test = train_test_split(\n",
    "    X, y, bins,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=bins\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "train_bin_counts = pd.Series(bins_train).value_counts().sort_index()\n",
    "minority_bin_size = train_bin_counts.min()\n",
    "print(\"Train bin counts:\\n\", train_bin_counts)\n",
    "print(f\"Smallest bin size = {minority_bin_size}\\n\")\n",
    "\n",
    "\n",
    "def create_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "keras_reg = KerasRegressor(build_fn=lambda: create_model(X_train_scaled.shape[1]), verbose=0)\n",
    "param_grid = {\n",
    "    'batch_size': [32, 64,128],\n",
    "    'epochs': [200, 500,800,1200]\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    estimator=keras_reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "r2_scores, mae_scores = [], []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(cv.split(X_train_scaled, bins_train), 1):\n",
    "    Xt, Xv = X_train_scaled[tr_idx], X_train_scaled[val_idx]\n",
    "    yt, yv = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "    bins_tr = bins_train.iloc[tr_idx]\n",
    "\n",
    "    fold_counts = pd.Series(bins_tr).value_counts()\n",
    "    fold_min = fold_counts.min()\n",
    "\n",
    "    M = 5 \n",
    "    val_preds = np.zeros((len(Xv), M))\n",
    "\n",
    "    for i in range(M):\n",
    "        idxs = []\n",
    "        for b in fold_counts.index:\n",
    "            b_idxs = np.where(bins_tr == b)[0]\n",
    "            if len(b_idxs) <= fold_min:\n",
    "                sel = b_idxs\n",
    "            else:\n",
    "                sel = np.random.RandomState(100+i).choice(b_idxs, size=fold_min, replace=False)\n",
    "            idxs.append(sel)\n",
    "        idxs = np.concatenate(idxs)\n",
    "\n",
    "        model = create_model(Xt.shape[1])\n",
    "        model.fit(Xt[idxs], yt.iloc[idxs], epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "        val_preds[:, i] = model.predict(Xv).flatten()\n",
    "\n",
    "    yv_pred = val_preds.mean(axis=1)\n",
    "    r2_scores.append(r2_score(yv, yv_pred))\n",
    "    mae_scores.append(mean_absolute_error(yv, yv_pred))\n",
    "    print(f\" Fold {fold:>2}:   R²={r2_scores[-1]:.3f}, MAE={mae_scores[-1]:.1f}\")\n",
    "\n",
    "print(\"\\nValidation performance (mean ± std):\")\n",
    "print(f\" R²  : {np.mean(r2_scores):.3f} ± {np.std(r2_scores):.3f}\")\n",
    "print(f\" MAE : {np.mean(mae_scores):.1f} ± {np.std(mae_scores):.1f}\\n\")\n",
    "\n",
    "\n",
    "M_final = 30\n",
    "models = []\n",
    "\n",
    "for i in range(M_final):\n",
    "    idxs = []\n",
    "    for b in train_bin_counts.index:\n",
    "        b_idxs = np.where(bins_train == b)[0]\n",
    "        if len(b_idxs) <= minority_bin_size:\n",
    "            sel = b_idxs\n",
    "        else:\n",
    "            sel = np.random.RandomState(200+i).choice(b_idxs, size=minority_bin_size, replace=False)\n",
    "        idxs.append(sel)\n",
    "    idxs = np.concatenate(idxs)\n",
    "\n",
    "    model = create_model(X_train_scaled.shape[1])\n",
    "    model.fit(X_train_scaled[idxs], y_train.iloc[idxs], epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "    models.append(model)\n",
    "\n",
    "\n",
    "all_preds = np.column_stack([m.predict(X_test_scaled).flatten() for m in models])\n",
    "y_pred_mean = all_preds.mean(axis=1)\n",
    "y_pred_std  = all_preds.std(axis=1)\n",
    "\n",
    "\n",
    "print(\"Test performance:\")\n",
    "print(\" R²  :\", r2_score(y_test, y_pred_mean))\n",
    "print(\" MAE :\", mean_absolute_error(y_test, y_pred_mean))\n",
    "print(\" RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_mean)))\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.errorbar(\n",
    "    y_test, y_pred_mean,\n",
    "    yerr=y_pred_std,\n",
    "    fmt='o',\n",
    "    ecolor='lightgray',\n",
    "    capsize=2,\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    'r--', lw=1\n",
    ")\n",
    "plt.xlabel('Actual Mean Néel Temperature (K)')\n",
    "plt.ylabel('Predicted Mean Néel Temperature (K)')\n",
    "plt.title('Neural Network Ensemble Predictions ±1σ on TEST (Néel)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a264e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aadb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Predicted vs Actual Neel temperature Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da866095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "r2   = r2_score(y_test, y_pred_mean)\n",
    "mae  = mean_absolute_error(y_test, y_pred_mean)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_mean))\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"axes.titlesize\": 20,\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": \"Helvetica\",\n",
    "    \"legend.fontsize\": 13,\n",
    "    \"axes.linewidth\": 1.2,\n",
    "    \"xtick.major.width\": 1.1,\n",
    "    \"ytick.major.width\": 1.1,\n",
    "    \"grid.alpha\": 0.3,\n",
    "    \"grid.linestyle\": \"--\"\n",
    "})\n",
    "\n",
    "norm = plt.Normalize(vmin=y_pred_std.min(), vmax=y_pred_std.max())\n",
    "colors = cm.turbo(norm(y_pred_std))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.1, 6))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    y_test, y_pred_mean,\n",
    "    c=y_pred_std, cmap='turbo',\n",
    "    edgecolor='black', linewidth=0.25,\n",
    "    s=65, alpha=0.9\n",
    ")\n",
    "\n",
    "ax.errorbar(\n",
    "    y_test, y_pred_mean,\n",
    "    yerr=y_pred_std,\n",
    "    fmt='none',\n",
    "    ecolor='gray',\n",
    "    alpha=0.2,\n",
    "    capsize=2,\n",
    "    linewidth=0.6,\n",
    "    zorder=0\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    'r--', linewidth=1.5\n",
    ")\n",
    "\n",
    "x_min, x_max = y_test.min(), y_test.max()\n",
    "ax.set_xlim([x_min - 40, x_max + 40])\n",
    "ax.set_ylim([x_min - 40, x_max + 40])\n",
    "ax.set_xlabel('Actual Néel Temperature (K)', labelpad=10)\n",
    "ax.set_ylabel('Predicted Néel Temperature (K)', labelpad=10)\n",
    "ax.set_title('ENN with Stratified Undersampling', pad=20)\n",
    "\n",
    "stats_text = f\"R² = {r2:.2f}\\nMAE = {mae:.0f} K\\nRMSE = {rmse:.0f} K\"\n",
    "ax.text(\n",
    "    0.05, 0.95, stats_text,\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=14,\n",
    "    verticalalignment='top',\n",
    "    bbox=dict(facecolor='white', edgecolor='gray', boxstyle='round,pad=0.5')\n",
    ")\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax, pad=0.03)\n",
    "cbar.set_label('Prediction Std Deviation (K)', size=14)\n",
    "\n",
    "plt.tight_layout(pad=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAE distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import expon\n",
    "\n",
    "abs_errors = np.abs(y_test - y_pred_mean)\n",
    "mae = np.mean(abs_errors)\n",
    "mae_rounded = round(mae)\n",
    "\n",
    "loc, scale = expon.fit(abs_errors)\n",
    "\n",
    "cutoff = 300\n",
    "filtered_errors = abs_errors[abs_errors <= cutoff]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "counts, bins, _ = plt.hist(\n",
    "    filtered_errors, bins=30, density=True,\n",
    "    alpha=0.85, color='royalblue', label='Histogram'\n",
    ")\n",
    "\n",
    "x_vals = np.linspace(0, cutoff, 500)\n",
    "plt.plot(\n",
    "    x_vals, expon.pdf(x_vals, loc, scale),\n",
    "    'k-', lw=2, label='Fitted Exponential Distribution'\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    mae, color='red', linestyle='--', lw=2,\n",
    "    label=f'Mean Absolute Error: {mae_rounded} K'\n",
    ")\n",
    "\n",
    "plt.xlabel('Absolute Error (K)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Absolute Errors', fontsize=15)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.xlim(0, cutoff)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a843f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd111460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "n_ensembles = len(models)\n",
    "\n",
    "importances_mean = np.zeros(len(FEATURES))\n",
    "importances_std  = np.zeros(len(FEATURES))\n",
    "\n",
    "for model in models:\n",
    "    results = permutation_importance(\n",
    "        model,\n",
    "        X_test_scaled,\n",
    "        y_test,\n",
    "        n_repeats=30,\n",
    "        random_state=42,\n",
    "        scoring='neg_mean_squared_error'\n",
    "    )\n",
    "    importances_mean += results.importances_mean\n",
    "    importances_std  += results.importances_std\n",
    "\n",
    "importances_mean /= n_ensembles\n",
    "importances_std  /= n_ensembles\n",
    "\n",
    "imp_df = pd.DataFrame({\n",
    "    'feature': FEATURES,\n",
    "    'mean_import': importances_mean,\n",
    "    'std_import': importances_std\n",
    "}).sort_values('mean_import', ascending=False).reset_index(drop=True)\n",
    "\n",
    "TOP_N = 20\n",
    "top20 = imp_df.head(TOP_N).copy()\n",
    "\n",
    "pretty_names = {\n",
    "    'avg_magnetic_moment': 'Avg Magnetic Moment',\n",
    "    'Average_Weight': 'Avg Atomic Weight',\n",
    "    'Magnetic_proportion': 'Prop. of High Néel Temp Elements',\n",
    "    'Average_Electronegativity': 'Avg Electronegativity',\n",
    "    'Avg_Atomic_Number': 'Avg Atomic Number',\n",
    "    'Entropy': 'Avg Entropy',\n",
    "    'Rare_Earth_proportion': 'Proportion of Rare Earths',\n",
    "    'average_group': 'Avg Periodic Group',\n",
    "    'average_period': 'Avg Periodic Period',\n",
    "}\n",
    "top20['label'] = top20['feature'].map(pretty_names).fillna(top20['feature'])\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(\n",
    "    top20['label'][::-1],\n",
    "    top20['mean_import'][::-1],\n",
    "    xerr=top20['std_import'][::-1],\n",
    "    color='royalblue',\n",
    "    edgecolor='black',\n",
    "    capsize=3\n",
    ")\n",
    "plt.xlabel('Average Permutation Importance\\n(Ensemble Mean ± 1 SD)', fontsize=13)\n",
    "plt.title('Top-20 Feature Importances — Neural Network Ensemble (Néel Temperature Prediction)', fontsize=15)\n",
    "plt.grid(axis='both', linestyle='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9db3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556641c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a74979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381624c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d05e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40e150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
